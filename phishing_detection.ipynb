{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "phishing_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Classification into Phishing and Non-phishing sites**\n",
        "\n",
        "The dataset has 30 features and the result will be printed in the Result column as 1(legitimate) or -1(phishing).\n",
        "\n",
        "Each site is uniquely identified by a key value."
      ],
      "metadata": {
        "id": "UaPI8I7uMQ-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "ywvPvTrl-Of3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "traindata='https://raw.githubusercontent.com/kshitijabits/ML_Phishing/CSVs/Phising_Training_Dataset.csv'\n",
        "dftrain=pd.read_csv(traindata)\n",
        "\n",
        "testdata='https://raw.githubusercontent.com/kshitijabits/ML_Phishing/CSVs/Phising_Testing_Dataset.csv'\n",
        "dftest=pd.read_csv(testdata)\n",
        "\n",
        "#dftrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical aspects of the dataframe\n",
        "print(dftrain.describe())\n",
        "print()"
      ],
      "metadata": {
        "id": "0nQFsPzPMPIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllen=pd.get_dummies(dftrain['URL_Length'], drop_first=True, prefix='URL_len')\n",
        "dftrain=pd.concat([dftrain, urllen], axis = 1)\n",
        "\n",
        "hsd=pd.get_dummies(dftrain['having_Sub_Domain'], drop_first=True, prefix='Has_Subdomain')\n",
        "dftrain=pd.concat([dftrain, hsd], axis = 1)\n",
        "\n",
        "sslfs=pd.get_dummies(dftrain['SSLfinal_State'], drop_first=True, prefix='SSL_final')\n",
        "dftrain=pd.concat([dftrain, sslfs], axis = 1)\n",
        "\n",
        "uoa=pd.get_dummies(dftrain['URL_of_Anchor'], drop_first=True, prefix='URLofAnchor')\n",
        "dftrain=pd.concat([dftrain, uoa], axis = 1)\n",
        "\n",
        "litag=pd.get_dummies(dftrain['Links_in_tags'], drop_first=True, prefix='Tag_links')\n",
        "dftrain=pd.concat([dftrain, litag], axis = 1)\n",
        "\n",
        "sfh=pd.get_dummies(dftrain['SFH'], drop_first=True, prefix='SFH_column')\n",
        "dftrain=pd.concat([dftrain, sfh], axis = 1)\n",
        "\n",
        "traffic=pd.get_dummies(dftrain['web_traffic'], drop_first=True, prefix='traffic')\n",
        "dftrain=pd.concat([dftrain, traffic], axis = 1)\n",
        "\n",
        "lp2p=pd.get_dummies(dftrain['Links_pointing_to_page'], drop_first=True, prefix='Links_pointing2page')\n",
        "dftrain=pd.concat([dftrain, lp2p], axis = 1)\n",
        "\n",
        "# Dropping vars as we have created the dummies for it\n",
        "dftrain=dftrain.drop(['URL_Length','having_Sub_Domain','SSLfinal_State','URL_of_Anchor','Links_in_tags','SFH','web_traffic','Links_pointing_to_page'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "urllen1=pd.get_dummies(dftest['URL_Length'], drop_first=True, prefix='URL_len')\n",
        "dftest=pd.concat([dftest, urllen1], axis = 1)\n",
        "\n",
        "hsd1=pd.get_dummies(dftest['having_Sub_Domain'], drop_first=True, prefix='Has_Subdomain')\n",
        "dftest=pd.concat([dftest, hsd1], axis = 1)\n",
        "\n",
        "sslfs1=pd.get_dummies(dftest['SSLfinal_State'], drop_first=True, prefix='SSL_final')\n",
        "dftest=pd.concat([dftest, sslfs1], axis = 1)\n",
        "\n",
        "uoa1=pd.get_dummies(dftest['URL_of_Anchor'], drop_first=True, prefix='URLofAnchor')\n",
        "dftest=pd.concat([dftest, uoa1], axis = 1)\n",
        "\n",
        "litag1=pd.get_dummies(dftest['Links_in_tags'], drop_first=True, prefix='Tag_links')\n",
        "dftest=pd.concat([dftest, litag1], axis = 1)\n",
        "\n",
        "sfh1=pd.get_dummies(dftest['SFH'], drop_first=True, prefix='SFH_column')\n",
        "dftest=pd.concat([dftest, sfh1], axis = 1)\n",
        "\n",
        "traffic1=pd.get_dummies(dftest['web_traffic'], drop_first=True, prefix='traffic')\n",
        "dftest=pd.concat([dftest, traffic1], axis = 1)\n",
        "\n",
        "lp2p1=pd.get_dummies(dftest['Links_pointing_to_page'], drop_first=True, prefix='Links_pointing2page')\n",
        "dftest=pd.concat([dftest, lp2p1], axis = 1)\n",
        "\n",
        "# Dropping vars as we have created the dummies for it\n",
        "dftest=dftest.drop(['URL_Length','having_Sub_Domain','SSLfinal_State','URL_of_Anchor','Links_in_tags','SFH','web_traffic','Links_pointing_to_page'], axis=1)\n"
      ],
      "metadata": {
        "id": "Jkdu9His07Xh"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries to split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"\n",
        "# Putting feature variable to X\n",
        "X = dftrain.drop(['key','Result'], axis=1)\n",
        "X.head()\n",
        "\"\"\"\n",
        "dftest['Result']=0\n",
        "\n",
        "X_train, y_train = dftrain.drop(['key','Result'], axis=1), dftrain['Result']\n",
        "X_test, y_test = dftest, dftest['Result']"
      ],
      "metadata": {
        "id": "gFN3FXSB6oME"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Let's see the correlation matrix \n",
        "plt.figure(figsize = (20,10))        # Size of the figure\n",
        "sns.heatmap(dftrain.corr(),annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iX_qqVXM-rsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Logistic regression model\n",
        "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
        "logm1.fit().summary()"
      ],
      "metadata": {
        "id": "M3PdcZ25ENfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(estimator=LogisticRegression(),n_features_to_select=30)          \n",
        "rfe = rfe.fit(X_train, y_train)\n",
        "\n",
        "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
      ],
      "metadata": {
        "id": "ozN4ely6Eyav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = X_train.columns[rfe.support_]\n",
        "\n",
        "X_train_sm = sm.add_constant(X_train[col])\n",
        "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
        "res = logm2.fit()\n",
        "res.summary()"
      ],
      "metadata": {
        "id": "taBgd3wEG-u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the predicted values on the train set\n",
        "y_train_pred = res.predict(X_train_sm)\n",
        "y_train_pred[:10]"
      ],
      "metadata": {
        "id": "sPFdhf2FHTZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col1 = X_train.columns[rfe.support_]\n",
        "\n",
        "X_test_sm = sm.add_constant(X_test[col1])\n",
        "y_test = res.predict(X_test_sm)\n",
        "y_test[:10]\n",
        "\n",
        "# Creating a dataframe with the actual result flag and the predicted probabilities\n",
        "y_test_final = pd.DataFrame({'Result':y_test.values, 'Result_Prob':y_test})\n",
        "\n",
        "# Creating new column 'predicted' with 1 if Result_Prob > 0.5 else 0\n",
        "y_test_final['predicted'] = y_test_final.Result_Prob.map(lambda x: 1 if x > 0.5 else -1)\n",
        "\n",
        "finaldata=y_test_final.drop(['Result','Result_Prob'],1)\n",
        "finaldata.rename(columns={'predicted':'Result'}, inplace=True)\n",
        "finaldata.index = dftest['key']\n",
        "\n",
        "finaldata\n"
      ],
      "metadata": {
        "id": "us63dm_IvDbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the dataframe to a CSV\n",
        "finaldata.to_csv('Phishing_output.csv')"
      ],
      "metadata": {
        "id": "6M_pxTpa0pFH"
      },
      "execution_count": 263,
      "outputs": []
    }
  ]
}